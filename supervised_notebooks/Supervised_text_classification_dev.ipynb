{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Text Complexity Classifier - Dev\n",
    "\n",
    "## Dev notes\n",
    "\n",
    "This version of the notebook uses only the training csv. The goal is to remake the algorithms tested in the POC notebook, but using the full test data. Once trained they will be output to pickle files and the PRD notebook will grab those and generate predictions on the test data.\n",
    "\n",
    "\n",
    "## Data import and cleaning\n",
    "\n",
    "Primary goals here are getting data from the training data set and creating metrics that will convey the complexity of the text to our classifiers. There are 3 additional data sources as part of the Kaggle set that we used. The average of acquisition data set contains information gathered on around 50,000 words and contains each words lemmatized root and information about when that word the average age a person learns that word and the frequency of its use. The concreteness ratings contains a smaller number of words, but gives an impression of how much a word is associated with a particular idea. Finally the dale_chall data set contains a list of words that are considered 'basic english'.\n",
    "\n",
    "\n",
    "#### Dependencies\n",
    "\n",
    "Below are the datacleaning dependencies only. A longer list of imports for modeling is at the start of that section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import statistics as stats\n",
    "import pickle as pkl\n",
    "from nltk.corpus import stopwords  \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score \n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('WikiLarge_Train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Control of how much data we train with\n",
    "\n",
    "The train and test dataframes can be adjusted here to either be the full data or a random sample of the full data set. For efficiency, the random samples were used for initial investigation of appropriate models and some parameter tuning. Final tuning and model selection was based on the training done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Data\n",
    "\n",
    "### Word Tokenization and Stop Word Removal\n",
    "\n",
    "Metrics are created out of the word count and the syllable counts within the text. However, stop words are common and often only one syllable so they were removed. The metrics will therefore be based only on the remaining words. This will through off the flesch_kincaid score from what it might have been calculated, but when trying to predict text complexity, stop words can be noisy and non-informative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_remove_stops(text):\n",
    "    text_list = word_tokenize(text)\n",
    "    stop_word_set = set(stopwords.words('english'))\n",
    "    clean_list = [word.lower() for word in text_list if word.lower() not in stop_word_set]\n",
    "    clean_list = [word for word in clean_list if re.match('^[a-z]+$', word)]\n",
    "    \n",
    "    return clean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There is manuscript evidence that Austen conti...</td>\n",
       "      <td>1</td>\n",
       "      <td>[manuscript, evidence, austen, continued, work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In a remarkable comparative analysis , Mandaea...</td>\n",
       "      <td>1</td>\n",
       "      <td>[remarkable, comparative, analysis, mandaean, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Before Persephone was released to Hermes , who...</td>\n",
       "      <td>1</td>\n",
       "      <td>[persephone, released, hermes, sent, retrieve,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cogeneration plants are commonly found in dist...</td>\n",
       "      <td>1</td>\n",
       "      <td>[cogeneration, plants, commonly, found, distri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geneva -LRB- , ; , ; , ; ; -RRB- is the second...</td>\n",
       "      <td>1</td>\n",
       "      <td>[geneva, city, switzerland, populous, city, ro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text  label  \\\n",
       "0  There is manuscript evidence that Austen conti...      1   \n",
       "1  In a remarkable comparative analysis , Mandaea...      1   \n",
       "2  Before Persephone was released to Hermes , who...      1   \n",
       "3  Cogeneration plants are commonly found in dist...      1   \n",
       "4  Geneva -LRB- , ; , ; , ; ; -RRB- is the second...      1   \n",
       "\n",
       "                                          clean_text  \n",
       "0  [manuscript, evidence, austen, continued, work...  \n",
       "1  [remarkable, comparative, analysis, mandaean, ...  \n",
       "2  [persephone, released, hermes, sent, retrieve,...  \n",
       "3  [cogeneration, plants, commonly, found, distri...  \n",
       "4  [geneva, city, switzerland, populous, city, ro...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['clean_text'] = df_train['original_text'].apply(tokenize_and_remove_stops)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Syllable count\n",
    "While the age of acquisition data source has a syllable count attached to each word, it remains the case that not all words in the texts were in that data source. This syllable counter was retrieved from stack overflow and validated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllable_count(clean_text_list):\n",
    "    count = 0\n",
    "    for word in clean_text_list:\n",
    "        word = word.lower()\n",
    "        vowels = \"aeiouy\"\n",
    "        if word[0] in vowels:\n",
    "            count += 1\n",
    "        for index in range(1, len(word)):\n",
    "            if word[index] in vowels and word[index - 1] not in vowels:\n",
    "                count += 1\n",
    "        if word.endswith(\"e\"):\n",
    "            count -= 1\n",
    "        if count == 0:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>syllables</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_syll_per_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There is manuscript evidence that Austen conti...</td>\n",
       "      <td>1</td>\n",
       "      <td>[manuscript, evidence, austen, continued, work...</td>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "      <td>1.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In a remarkable comparative analysis , Mandaea...</td>\n",
       "      <td>1</td>\n",
       "      <td>[remarkable, comparative, analysis, mandaean, ...</td>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>2.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Before Persephone was released to Hermes , who...</td>\n",
       "      <td>1</td>\n",
       "      <td>[persephone, released, hermes, sent, retrieve,...</td>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cogeneration plants are commonly found in dist...</td>\n",
       "      <td>1</td>\n",
       "      <td>[cogeneration, plants, commonly, found, distri...</td>\n",
       "      <td>57</td>\n",
       "      <td>27</td>\n",
       "      <td>2.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geneva -LRB- , ; , ; , ; ; -RRB- is the second...</td>\n",
       "      <td>1</td>\n",
       "      <td>[geneva, city, switzerland, populous, city, ro...</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>2.375000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text  label  \\\n",
       "0  There is manuscript evidence that Austen conti...      1   \n",
       "1  In a remarkable comparative analysis , Mandaea...      1   \n",
       "2  Before Persephone was released to Hermes , who...      1   \n",
       "3  Cogeneration plants are commonly found in dist...      1   \n",
       "4  Geneva -LRB- , ; , ; , ; ; -RRB- is the second...      1   \n",
       "\n",
       "                                          clean_text  syllables  word_count  \\\n",
       "0  [manuscript, evidence, austen, continued, work...         33          17   \n",
       "1  [remarkable, comparative, analysis, mandaean, ...         33          13   \n",
       "2  [persephone, released, hermes, sent, retrieve,...         38          19   \n",
       "3  [cogeneration, plants, commonly, found, distri...         57          27   \n",
       "4  [geneva, city, switzerland, populous, city, ro...         19           8   \n",
       "\n",
       "   avg_syll_per_word  \n",
       "0           1.941176  \n",
       "1           2.538462  \n",
       "2           2.000000  \n",
       "3           2.111111  \n",
       "4           2.375000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['syllables'] = df_train['clean_text'].apply(syllable_count)\n",
    "df_train['word_count'] = df_train['clean_text'].apply(lambda x: len(x))\n",
    "df_train['avg_syll_per_word'] = df_train['syllables'] / df_train['word_count']\n",
    "df_train['avg_syll_per_word'] = df_train['avg_syll_per_word'].fillna(0)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flesch_kincaid ease\n",
    "\n",
    "This is a relatively common metric for text complexity based solely on the number of words per sentence. If for some reason the score fails to calculate (happens on just a couple rows in the full data set), the mean of all successful scores is placed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flesch_kincaid_ease(row):\n",
    "    return round(206.835 - 1.015*(row['word_count']) - 84.6*(row['avg_syll_per_word']),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>syllables</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_syll_per_word</th>\n",
       "      <th>fc_ease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There is manuscript evidence that Austen conti...</td>\n",
       "      <td>1</td>\n",
       "      <td>[manuscript, evidence, austen, continued, work...</td>\n",
       "      <td>33</td>\n",
       "      <td>17</td>\n",
       "      <td>1.941176</td>\n",
       "      <td>25.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In a remarkable comparative analysis , Mandaea...</td>\n",
       "      <td>1</td>\n",
       "      <td>[remarkable, comparative, analysis, mandaean, ...</td>\n",
       "      <td>33</td>\n",
       "      <td>13</td>\n",
       "      <td>2.538462</td>\n",
       "      <td>-21.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Before Persephone was released to Hermes , who...</td>\n",
       "      <td>1</td>\n",
       "      <td>[persephone, released, hermes, sent, retrieve,...</td>\n",
       "      <td>38</td>\n",
       "      <td>19</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>18.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cogeneration plants are commonly found in dist...</td>\n",
       "      <td>1</td>\n",
       "      <td>[cogeneration, plants, commonly, found, distri...</td>\n",
       "      <td>57</td>\n",
       "      <td>27</td>\n",
       "      <td>2.111111</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geneva -LRB- , ; , ; , ; ; -RRB- is the second...</td>\n",
       "      <td>1</td>\n",
       "      <td>[geneva, city, switzerland, populous, city, ro...</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>-2.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text  label  \\\n",
       "0  There is manuscript evidence that Austen conti...      1   \n",
       "1  In a remarkable comparative analysis , Mandaea...      1   \n",
       "2  Before Persephone was released to Hermes , who...      1   \n",
       "3  Cogeneration plants are commonly found in dist...      1   \n",
       "4  Geneva -LRB- , ; , ; , ; ; -RRB- is the second...      1   \n",
       "\n",
       "                                          clean_text  syllables  word_count  \\\n",
       "0  [manuscript, evidence, austen, continued, work...         33          17   \n",
       "1  [remarkable, comparative, analysis, mandaean, ...         33          13   \n",
       "2  [persephone, released, hermes, sent, retrieve,...         38          19   \n",
       "3  [cogeneration, plants, commonly, found, distri...         57          27   \n",
       "4  [geneva, city, switzerland, populous, city, ro...         19           8   \n",
       "\n",
       "   avg_syll_per_word  fc_ease  \n",
       "0           1.941176    25.36  \n",
       "1           2.538462   -21.11  \n",
       "2           2.000000    18.35  \n",
       "3           2.111111     0.83  \n",
       "4           2.375000    -2.21  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['fc_ease'] = df_train.apply(flesch_kincaid_ease, axis = 1)\n",
    "\n",
    "fc_mean = df_train['fc_ease'].dropna().mean()\n",
    "df_train['fc_ease'] = df_train['fc_ease'].fillna(fc_mean)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick check to see if there is a difference between the two labels on this metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    25.707627\n",
       "1    15.813260\n",
       "Name: fc_ease, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('label')['fc_ease'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concreteness Ratings\n",
    "\n",
    "The cell below reads the concreteness data source and converts it into a dictionary with the word as the key and the measure values as entries in a nested dictionary. This allows me to calculate averages for a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Word  Bigram  Conc.M  Conc.SD  Unknown  Total  Percent_known  \\\n",
      "0  roadsweeper       0    4.85     0.37        1     27           0.96   \n",
      "\n",
      "   SUBTLEX Dom_Pos  non_basic  \n",
      "0        0       0          1  \n",
      "3.0363\n"
     ]
    }
   ],
   "source": [
    "df_conc = pd.read_csv('Concreteness_ratings_Brysbaert_et_al_BRM.txt', sep = '\\t').fillna('0')\n",
    "basic_list = pd.read_csv('dale_chall.txt')['a'].to_list()\n",
    "\n",
    "\n",
    "df_conc['non_basic'] = df_conc['Word'].apply(lambda x: 0 if x in basic_list else 1)\n",
    "mean_conc = round(df_conc['Conc.M'].mean(), 4)\n",
    "print(df_conc.head(1))\n",
    "print(mean_conc)\n",
    "\n",
    "conc_keys = df_conc['Word'].tolist()\n",
    "\n",
    "dict_list = df_conc.set_index('Word').to_dict(orient = 'records')\n",
    "\n",
    "conc_dict = {}\n",
    "\n",
    "for i in range(len(conc_keys)):\n",
    "    conc_dict[conc_keys[i]] = dict_list[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age of Acquisition\n",
    "\n",
    "Similar to the concreteness data set, the cell below gets the desired measures from the AoA data source into a dictionary for use in the metric calculations. Slightly different is that the AoA data source also has a column for alternative spellings. If the alternative spelling listed is different then the primary spelling, that spelling is added to the final dictionary as a unique entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age = pd.read_csv('AoA_51715_words.csv')\n",
    "df_age['non_basic'] = df_age['Lemma_highest_PoS'].apply(lambda x: 0 if x in basic_list else 1)\n",
    "#print(df_age.head())\n",
    "\n",
    "mean_aoa = round(df_age['AoA_Kup_lem'].mean(), 4)\n",
    "mean_perc_known = round(df_age['Perc_known_lem'].mean(),4)\n",
    "med_freq = df_age['Freq_pm'].median()\n",
    "\n",
    "#print(mean_aoa, mean_perc_known, med_freq)\n",
    "\n",
    "age_keys = df_age['Word'].to_list()\n",
    "age_alt_keys = df_age['Alternative.spelling'].to_list()\n",
    "\n",
    "df_columns_for_dict = df_age[['Freq_pm', 'Dom_PoS_SUBTLEX', 'AoA_Kup_lem', 'Perc_known_lem', 'non_basic']].copy()\n",
    "df_columns_for_dict.columns = ['freq', 'pos', 'aoa', 'perc_known', 'non_basic']\n",
    "dict_list = df_columns_for_dict.to_dict(orient = 'records')\n",
    "\n",
    "\n",
    "age_dict = {}\n",
    "for i in range(len(age_keys)):\n",
    "    age_dict[age_keys[i]] = dict_list[i]\n",
    "\n",
    "for i in range(len(age_alt_keys)):\n",
    "    if age_alt_keys[i] not in age_dict:\n",
    "        age_dict[age_alt_keys[i]] = dict_list[i]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric calcuations\n",
    "\n",
    "The goal of the functions below is to get the average entry for each clean text entry in df_train. The percent_known is located in both data sources, so the larger data source (age of acquisition) is checked first. Frequency has a such heavy outliers on the high end, that median was selected instead of mean. If a word cannot be found the means of the features are substituted (median for frequency). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_conc(text):\n",
    "    sum_conc = 0\n",
    "    word_count = max(len(text), 1)\n",
    "    for word in text:\n",
    "        try:\n",
    "            sum_conc += conc_dict[word]['Conc.M']\n",
    "        except:\n",
    "            sum_conc += mean_conc\n",
    "            \n",
    "    return round(sum_conc / word_count, 4)\n",
    "\n",
    "def get_mean_aoa(text):\n",
    "    sum_aoa = 0\n",
    "    word_count = max(len(text), 1)\n",
    "    for word in text:\n",
    "        try:\n",
    "            sum_aoa += age_dict[word]['aoa']\n",
    "        except:\n",
    "            sum_aoa += mean_aoa\n",
    "            \n",
    "    return round(sum_aoa / word_count, 4)\n",
    "\n",
    "def get_mean_perc(text):\n",
    "    sum_perc = 0\n",
    "    word_count = max(len(text), 1)\n",
    "    for word in text:\n",
    "        try:\n",
    "            sum_perc += age_dict[word]['perc_known']\n",
    "        except:\n",
    "            try:\n",
    "                sum_perc += conc_dict[word]['Percent_known']\n",
    "            except:\n",
    "                sum_perc += mean_perc_known\n",
    "                \n",
    "    return round(sum_perc / word_count, 4)\n",
    "\n",
    "def get_mean_freq(text):\n",
    "    list_freq = []\n",
    "    for word in text:\n",
    "        try:\n",
    "            list_freq.append(age_dict[word]['freq'])\n",
    "        except:\n",
    "            list_freq.append(med_freq)\n",
    "    \n",
    "    if not list_freq:\n",
    "        list_freq.append(0)\n",
    "            \n",
    "    return stats.median(list_freq)\n",
    "\n",
    "def count_non_basic(text):\n",
    "    count = 0\n",
    "    for word in text:\n",
    "        try:\n",
    "            count += age_dict[word]['non_basic']\n",
    "        except:\n",
    "            try:\n",
    "                count += conc_dict[word]['non_basic']\n",
    "            except:\n",
    "                count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['mean_conc'] = df_train['clean_text'].apply(get_mean_conc)\n",
    "df_train['mean_aoa'] = df_train['clean_text'].apply(get_mean_aoa)\n",
    "df_train['mean_perc_known'] = df_train['clean_text'].apply(get_mean_perc)\n",
    "df_train['mean_freq'] = df_train['clean_text'].apply(get_mean_freq)\n",
    "df_train['non_basic_words'] = df_train['clean_text'].apply(count_non_basic)\n",
    "df_train = df_train.fillna(0)\n",
    "#df_train.replace([np.inf, -np.inf], np.nan).isnull().sum() #sanity check for nulls or infs\n",
    "\n",
    "#df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tfidf Logistic Regression Probablity\n",
    "\n",
    "The goal here is to train a logistic regresssion classifier on the tfidf vectors of the lemmatized words remaining in the cleaned text. Once trained, it will be used to predict the probability of the class. This probablity will be used as a feature along with other text based features calculated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lem_combine(text_list):\n",
    "    lem = WordNetLemmatizer()\n",
    "    lem_word = []\n",
    "    for word in text_list:\n",
    "        lem_word.append(lem.lemmatize(word))\n",
    "        \n",
    "    return (' '.join(word for word in lem_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['lem_text'] = df_train['clean_text'].apply(lem_combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = 'english', ngram_range = (1,3), max_features = 30000)\n",
    "\n",
    "X_vec = vectorizer.fit_transform(df_train['lem_text'])\n",
    "y_vec = df_train['label']\n",
    "\n",
    "log_vec = LogisticRegression(max_iter = 1000)\n",
    "log_vec.fit(X_vec, y_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['logreg_prob'] = [num[0] for num in log_vec.predict_proba(X_vec)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Word2Vec Average Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\e131353\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "w2v = Word2Vec(df_train['lem_text'].apply(lambda x: x.split()))\n",
    "\n",
    "\n",
    "def document_vector(text):\n",
    "    doc = [word for word in text.split() if word in w2v.wv.vocab]\n",
    "    if len(doc) == 0:\n",
    "        doc.append('he')\n",
    "    return np.mean(w2v[doc])\n",
    "\n",
    "df_train['w2v'] = df_train.lem_text.apply(document_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final X and y for model\n",
    "\n",
    "Below is a list of the columns being used to make X and y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[['word_count', 'avg_syll_per_word', 'fc_ease', 'mean_conc', 'mean_aoa', 'mean_perc_known', 'mean_freq', 'non_basic_words', 'logreg_prob', 'w2v']]\n",
    "y_train = df_train['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier (high performer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=100, weights='distance')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_neighbors =100, weights = 'distance')\n",
    "knn_clf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('log_reg.pkl', 'wb') as handle:\n",
    "    pkl.dump(log_vec, handle, protocol = pkl.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('knn.pkl', 'wb') as handle:\n",
    "    pkl.dump(knn_clf, handle, protocol = pkl.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('vectorizer.pkl', 'wb') as handle:\n",
    "    pkl.dump(vectorizer, handle, protocol = pkl.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('aoa.pkl', 'wb') as handle:\n",
    "    pkl.dump(age_dict, handle, protocol = pkl.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('concrete.pkl', 'wb') as handle:\n",
    "    pkl.dump(conc_dict, handle, protocol = pkl.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('w2v.pkl', 'wb') as handle:\n",
    "    pkl.dump(w2v, handle, protocol = pkl.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    \n",
    "misc_dict = {\n",
    "    'mean_conc' : mean_conc,\n",
    "    'mean_aoa' : mean_aoa,\n",
    "    'mean_perc_known' : mean_perc_known,\n",
    "    'med_freq' : med_freq\n",
    "    \n",
    "}\n",
    "\n",
    "with open('misc.pkl', 'wb') as handle:\n",
    "    pkl.dump(misc_dict, handle, protocol = pkl.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
